{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 迁移学习\n",
    "主要参考于[DeepLearning.ai课程](https://github.com/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%206%20-%20Lesson%203%20-%20Notebook.ipynb)\n",
    "\n",
    "**迁移学习：**有现存的已经在很多数据上训练过的模型，从运用这些模型从中学习到特征，用于自己的项目。\n",
    "\n",
    "通过获得已经训练好的神经网络模型和参数，并且重新训练全连接层，即可以用来解决其他实际问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 74, 74, 32)   864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 74, 74, 32)   96          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 74, 74, 32)   0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 72, 72, 32)   9216        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 72, 72, 32)   96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 72, 72, 32)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 72, 72, 64)   18432       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 72, 72, 64)   192         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 72, 72, 64)   0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 35, 35, 80)   240         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 35, 35, 80)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 33, 33, 192)  138240      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 33, 33, 192)  576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 33, 33, 192)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 16, 16, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 16, 16, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 16, 16, 96)   55296       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 16, 16, 48)   144         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 16, 16, 96)   288         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 16, 16, 48)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 16, 16, 96)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 16, 16, 64)   76800       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 16, 16, 96)   82944       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 16, 16, 64)   192         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 16, 16, 64)   192         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 16, 16, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 16, 16, 32)   96          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 16, 16, 64)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 16, 16, 64)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 16, 16, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 16, 16, 32)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_193[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 16, 16, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 16, 16, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 16, 16, 96)   55296       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 16, 16, 48)   144         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 16, 16, 96)   288         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 16, 16, 48)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 16, 16, 96)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 16, 16, 64)   76800       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 16, 16, 96)   82944       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 16, 16, 64)   192         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 16, 16, 64)   192         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 16, 16, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 16, 16, 64)   192         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 16, 16, 64)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 16, 16, 64)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 16, 16, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 16, 16, 64)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 16, 16, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 16, 16, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 16, 16, 96)   55296       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 16, 16, 48)   144         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 16, 16, 96)   288         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 16, 16, 48)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 16, 16, 96)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 16, 16, 64)   76800       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 16, 16, 96)   82944       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 16, 16, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 16, 16, 64)   192         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 16, 16, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 16, 16, 64)   192         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 16, 16, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 16, 16, 64)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 16, 16, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 16, 16, 64)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 16, 16, 64)   192         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 16, 16, 64)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 16, 16, 96)   55296       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 16, 16, 96)   288         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 16, 16, 96)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 7, 7, 96)     82944       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 7, 7, 384)    1152        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 7, 7, 96)     288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 7, 7, 384)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 7, 7, 96)     0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_214[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 7, 7, 128)    384         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 7, 7, 128)    0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 7, 7, 128)    114688      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 7, 7, 128)    384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 7, 7, 128)    114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 7, 7, 128)    384         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 7, 7, 128)    384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 7, 7, 128)    0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 7, 7, 128)    0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 7, 7, 128)    114688      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 7, 7, 128)    114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 7, 7, 128)    384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 7, 7, 128)    384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 7, 7, 128)    0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 7, 7, 128)    0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 7, 7, 192)    172032      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 7, 7, 192)    172032      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 7, 7, 192)    576         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 7, 7, 192)    576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 7, 7, 192)    576         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 7, 7, 192)    576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 7, 7, 192)    0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 7, 7, 192)    0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 7, 7, 192)    0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 7, 7, 192)    0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 7, 7, 160)    480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 7, 7, 160)    0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 7, 7, 160)    179200      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 7, 7, 160)    480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 7, 7, 160)    0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 7, 7, 160)    179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 7, 7, 160)    480         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 7, 7, 160)    480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 7, 7, 160)    0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 7, 7, 160)    0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 7, 7, 160)    179200      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 7, 7, 160)    179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 7, 7, 160)    480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 7, 7, 160)    480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 7, 7, 160)    0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 7, 7, 160)    0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 7, 7, 192)    215040      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 7, 7, 192)    215040      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 7, 7, 192)    576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 7, 7, 192)    576         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 7, 7, 192)    576         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 7, 7, 192)    576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 7, 7, 192)    0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 7, 7, 192)    0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 7, 7, 192)    0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 7, 7, 192)    0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_228[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 activation_236[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 7, 7, 160)    480         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 7, 7, 160)    0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 7, 7, 160)    179200      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 7, 7, 160)    480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 7, 7, 160)    0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 7, 7, 160)    179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 7, 7, 160)    480         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 7, 7, 160)    480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 7, 7, 160)    0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 7, 7, 160)    0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 7, 7, 160)    179200      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 7, 7, 160)    179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 7, 7, 160)    480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 7, 7, 160)    480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 7, 7, 160)    0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 7, 7, 160)    0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 7, 7, 192)    215040      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 7, 7, 192)    215040      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 7, 7, 192)    576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 7, 7, 192)    576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 7, 7, 192)    576         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 7, 7, 192)    576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 7, 7, 192)    0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 7, 7, 192)    0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 7, 7, 192)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 7, 7, 192)    0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_238[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "                                                                 activation_246[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 7, 7, 192)    576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 7, 7, 192)    0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 7, 7, 192)    258048      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 7, 7, 192)    576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 7, 7, 192)    0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 7, 7, 192)    258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 7, 7, 192)    576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 7, 7, 192)    576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 7, 7, 192)    0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 7, 7, 192)    0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 7, 7, 192)    258048      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 7, 7, 192)    258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 7, 7, 192)    576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 7, 7, 192)    576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 7, 7, 192)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 7, 7, 192)    0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 7, 7, 192)    258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 7, 7, 192)    258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 7, 7, 192)    576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 7, 7, 192)    576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 7, 7, 192)    576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 7, 7, 192)    576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 7, 7, 192)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 7, 7, 192)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 7, 7, 192)    0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 7, 7, 192)    0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 7, 7, 192)    576         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 7, 7, 192)    0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 7, 7, 192)    258048      activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 7, 7, 192)    576         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 7, 7, 192)    0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 7, 7, 192)    258048      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 7, 7, 192)    576         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 7, 7, 192)    576         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 7, 7, 192)    0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 7, 7, 192)    0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 3, 3, 320)    552960      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 3, 3, 192)    331776      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 3, 3, 320)    960         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 3, 3, 192)    576         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 3, 3, 320)    0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 3, 3, 192)    0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_259[0][0]             \n",
      "                                                                 activation_263[0][0]             \n",
      "                                                                 max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 3, 3, 448)    1344        conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 3, 3, 448)    0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 3, 3, 384)    1548288     activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 3, 3, 384)    1152        conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 3, 3, 384)    1152        conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 3, 3, 384)    0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 3, 3, 384)    0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 3, 3, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 3, 3, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 3, 3, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 3, 3, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 3, 3, 384)    1152        conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 3, 3, 384)    1152        conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 3, 3, 384)    1152        conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 3, 3, 384)    1152        conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 3, 3, 320)    960         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 3, 3, 384)    0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 3, 3, 384)    0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 3, 3, 384)    0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 3, 3, 384)    0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 3, 3, 192)    576         conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 3, 3, 320)    0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_266[0][0]             \n",
      "                                                                 activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3, 3, 768)    0           activation_270[0][0]             \n",
      "                                                                 activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 3, 3, 192)    0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_264[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 3, 3, 448)    1344        conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 3, 3, 448)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 3, 3, 384)    1548288     activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 3, 3, 384)    1152        conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 3, 3, 384)    1152        conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 3, 3, 384)    0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 3, 3, 384)    0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 3, 3, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 3, 3, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 3, 3, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 3, 3, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 3, 3, 384)    1152        conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 3, 3, 384)    1152        conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 3, 3, 384)    1152        conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 3, 3, 384)    1152        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 3, 3, 320)    960         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 3, 3, 384)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 3, 3, 384)    0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 3, 3, 384)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 3, 3, 384)    0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
      "                                                                 activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 activation_281[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n",
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "local_weights_file = 'tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "# 使用keras内置的InceptionV3模型\n",
    "pre_trained_model = InceptionV3(input_shape=(150,150,3),\n",
    "                                # 初始化的V3在第一层具有一个全连接层，\n",
    "                                # 使用include_top=False将其忽略\n",
    "                                # 直接进入卷积层\n",
    "                               include_top=False,\n",
    "                               # 表示不需要内置建立权重 \n",
    "                               weights = None)\n",
    "\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# 遍历模型并且设置为：这些层次将不用于训练权重，而是采用之前加载的权重\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "pre_trained_model.summary()\n",
    "\n",
    "# 为了获得更多的特征，选择mixed7作为卷积层的最后一层\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# 定义一个新的模型\n",
    "# 展平last_output\n",
    "x = layers.Flatten()(last_output)\n",
    "# 添加一层全连接层\n",
    "x = layers.Dense(1024,activation='relu')(x)\n",
    "# 添加一层Dropout层\n",
    "# 防止过拟合\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "# 最后一层\n",
    "x = layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "# 使用Model类创建模型：传递之前创建的输入和图层定义\n",
    "model = Model(pre_trained_model.input,x)\n",
    "\n",
    "# 编译模型：\n",
    "model.compile(optimizer = RMSprop(lr=0.0001),\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 生成训练数据的生成器\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = 'tmp/cats_and_dogs_filtered.zip'\n",
    "\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "\n",
    "zip_ref.extractall('tmp')\n",
    "zip_ref.close()\n",
    "\n",
    "base_dir = 'tmp/cats_and_dogs_filtered'\n",
    "\n",
    "train_dir = os.path.join( base_dir, 'train')\n",
    "validation_dir = os.path.join( base_dir, 'validation')\n",
    "\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats') \n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs') \n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats') \n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "train_cat_fnames = os.listdir(train_cats_dir)\n",
    "train_dog_fnames = os.listdir(train_dogs_dir)\n",
    "\n",
    "# 在生成器中添加数据扩增的参数\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# 验证集不应该使用数据扩增\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "# 以20的批大小输出的图片生成器\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary', \n",
    "                                                    target_size = (150, 150))     \n",
    "\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                          batch_size  = 20,\n",
    "                                                          class_mode  = 'binary', \n",
    "                                                          target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "100/100 - 299s - loss: 0.5282 - accuracy: 0.7545 - val_loss: 0.4792 - val_accuracy: 0.8700\n",
      "Epoch 2/20\n",
      "100/100 - 323s - loss: 0.3744 - accuracy: 0.8315 - val_loss: 0.3777 - val_accuracy: 0.9190\n",
      "Epoch 3/20\n",
      "100/100 - 291s - loss: 0.3448 - accuracy: 0.8495 - val_loss: 0.3161 - val_accuracy: 0.9360\n",
      "Epoch 4/20\n",
      "100/100 - 281s - loss: 0.3287 - accuracy: 0.8590 - val_loss: 0.4631 - val_accuracy: 0.9240\n",
      "Epoch 5/20\n",
      "100/100 - 277s - loss: 0.3346 - accuracy: 0.8565 - val_loss: 0.2584 - val_accuracy: 0.9590\n",
      "Epoch 6/20\n",
      "100/100 - 263s - loss: 0.3048 - accuracy: 0.8705 - val_loss: 0.2982 - val_accuracy: 0.9560\n",
      "Epoch 7/20\n",
      "100/100 - 227s - loss: 0.2931 - accuracy: 0.8790 - val_loss: 0.2676 - val_accuracy: 0.9670\n",
      "Epoch 8/20\n",
      "100/100 - 239s - loss: 0.2873 - accuracy: 0.8740 - val_loss: 0.4323 - val_accuracy: 0.9500\n",
      "Epoch 9/20\n",
      "100/100 - 228s - loss: 0.2823 - accuracy: 0.8825 - val_loss: 0.4696 - val_accuracy: 0.9450\n",
      "Epoch 10/20\n",
      "100/100 - 228s - loss: 0.2800 - accuracy: 0.8870 - val_loss: 0.6612 - val_accuracy: 0.9310\n",
      "Epoch 11/20\n",
      "100/100 - 228s - loss: 0.2841 - accuracy: 0.8875 - val_loss: 0.4158 - val_accuracy: 0.9480\n",
      "Epoch 12/20\n",
      "100/100 - 227s - loss: 0.2624 - accuracy: 0.8910 - val_loss: 0.4528 - val_accuracy: 0.9530\n",
      "Epoch 13/20\n",
      "100/100 - 229s - loss: 0.2737 - accuracy: 0.8850 - val_loss: 0.6054 - val_accuracy: 0.9410\n",
      "Epoch 14/20\n",
      "100/100 - 227s - loss: 0.2521 - accuracy: 0.9050 - val_loss: 0.5195 - val_accuracy: 0.9510\n",
      "Epoch 15/20\n",
      "100/100 - 228s - loss: 0.2419 - accuracy: 0.9120 - val_loss: 0.4045 - val_accuracy: 0.9620\n",
      "Epoch 16/20\n",
      "100/100 - 227s - loss: 0.2421 - accuracy: 0.9045 - val_loss: 0.4449 - val_accuracy: 0.9570\n",
      "Epoch 17/20\n",
      "100/100 - 226s - loss: 0.2659 - accuracy: 0.8910 - val_loss: 0.4362 - val_accuracy: 0.9640\n",
      "Epoch 18/20\n",
      "100/100 - 227s - loss: 0.2413 - accuracy: 0.9010 - val_loss: 0.4297 - val_accuracy: 0.9610\n",
      "Epoch 19/20\n",
      "100/100 - 227s - loss: 0.2520 - accuracy: 0.9015 - val_loss: 0.5228 - val_accuracy: 0.9540\n",
      "Epoch 20/20\n",
      "100/100 - 226s - loss: 0.2388 - accuracy: 0.9070 - val_loss: 0.4514 - val_accuracy: 0.9590\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "\n",
    "history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = 100,# 2000 / 100 =100\n",
    "            epochs = 20,\n",
    "            validation_steps = 50,\n",
    "            verbose = 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化精确度和损失\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
